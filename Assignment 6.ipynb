{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420570a8-7e02-460e-8187-a6c1b9d92826",
   "metadata": {},
   "source": [
    "# Assignment 6 - 24/01/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4af571-955c-483f-9ab6-505bb5cf17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799bcad0-8474-4be8-9ba4-0a579ffba636",
   "metadata": {},
   "source": [
    "### 1. Data Preparation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69b58b3-e91c-4b61-adf7-7ae1d15401de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        work class  final weight education level  education years  \\\n",
      "0   39         State-gov         77516       Bachelors               13   \n",
      "1   50  Self-emp-not-inc         83311       Bachelors               13   \n",
      "2   38           Private        215646         HS-grad                9   \n",
      "3   53           Private        234721            11th                7   \n",
      "4   28           Private        338409       Bachelors               13   \n",
      "\n",
      "       marital status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital gain  capital loss  working hours per week native country income  \n",
      "0          2174             0                      40  United-States  <=50K  \n",
      "1             0             0                      13  United-States  <=50K  \n",
      "2             0             0                      40  United-States  <=50K  \n",
      "3             0             0                      40  United-States  <=50K  \n",
      "4             0             0                      40           Cuba  <=50K  \n",
      "age                          0\n",
      "work class                1836\n",
      "final weight                 0\n",
      "education level              0\n",
      "education years              0\n",
      "marital status               0\n",
      "occupation                1843\n",
      "relationship                 0\n",
      "race                         0\n",
      "sex                          0\n",
      "capital gain                 0\n",
      "capital loss                 0\n",
      "working hours per week       0\n",
      "native country             583\n",
      "income                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/belki/OneDrive - marmara.edu.tr/Masaüstü/Doktora/Advanced Data Analysis/Datasets/UCI Adult/adult.data\" \n",
    "# get data\n",
    "column_names = [\n",
    "    \"age\", \"work class\", \"final weight\", \"education level\", \"education years\", \n",
    "    \"marital status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "    \"capital gain\", \"capital loss\", \"working hours per week\", \"native country\", \"income\"\n",
    "]\n",
    "# rename variables\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, names=column_names, skipinitialspace=True) # skipinitialspace=True -> help to clean unnecessary spaces\n",
    "\n",
    "print(df.head())\n",
    "# check data if it works\n",
    "\n",
    "df.replace('?', np.nan, inplace=True) # I realized that missings are coded as ? so I remove them and make real NaNs.\n",
    "\n",
    "print(df.isnull().sum()) \n",
    "# check missings\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "# recode categorical to numeric\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "# normalization\n",
    "\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "# turn target variable into a binary one\n",
    "\n",
    "X = df.drop('income', axis=1)  # set predictors except target\n",
    "y = df['income']  # and target variable\n",
    "X = pd.get_dummies(X, drop_first=True) # transform catrgoric variables\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)\n",
    "# split data as test and train ( 70% for training, 30% for test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62428b2b-196f-4e6f-b20e-16744aaa2398",
   "metadata": {},
   "source": [
    "### 2. Model Implementation: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888801a-8b5c-4092-beef-82bff1d4fc79",
   "metadata": {},
   "source": [
    "##### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "187497d1-ff29-40fd-90a9-742e58820299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     17305\n",
      "           1       0.74      0.60      0.66      5487\n",
      "\n",
      "    accuracy                           0.85     22792\n",
      "   macro avg       0.81      0.77      0.78     22792\n",
      "weighted avg       0.85      0.85      0.85     22792\n",
      "\n",
      "Test performance (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      7415\n",
      "           1       0.74      0.59      0.66      2354\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, random_state=45)\n",
    "log_reg.fit(X_train, y_train)\n",
    "# model training\n",
    "\n",
    "y_pred_logreg = log_reg.predict(X_test)\n",
    "#prediction \n",
    "\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training performance (Logistic Regression):\\n\", classification_report(y_train, y_train_pred))\n",
    "#check the performance of training\n",
    "\n",
    "# Test seti performansı\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test performance (Logistic Regression):\\n\", classification_report(y_test, y_test_pred))\n",
    "#check the performance of test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f548a8-bba8-40a1-a901-cf7d78740aed",
   "metadata": {},
   "source": [
    "I print a classification report for the test set of the model. To check if there is an overfitting problem in the model, I also generate a report for the training set and compare the values. \n",
    "\n",
    "The accuracy value of the model is 0.85, which shows that the model correctly classified 85% of the test data. When we look at the class differences, the model is correct in 88% of its predictions for the income class of 50k and below (precision: 0.88). In addition, it really predicted 94% of the income class of 50k and below (recall: 0.94). On the other hand, the model is correct in 74% of its predictions for the income class of over 50k (precision: 0.74). Also, it predicted 59% of the income class of over 50k (recall: 0.59). The low precision and recall values ​​for the class above 50k caused the F1 score of this class (.066) to be lower than the class below 50k (0.91).\n",
    "\n",
    "Finally, the very small difference in training accuracy (85.21%) and test accuracy (85.16%) shows that there is no overfitting problem in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d18adc8-90a6-43bb-9308-4054a24cb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one is better? {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=45), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid.fit(X_train, y_train)\n",
    "# optimize C hyperparameter\n",
    "\n",
    "print(\"Which one is better?\", grid.best_params_)\n",
    "# see which one is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a002326f-7ce9-417d-a0ec-624d9e21f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized test performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      7415\n",
      "           1       0.75      0.58      0.65      2354\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_C = grid.best_params_['C']\n",
    "optimized_log_reg = LogisticRegression(C=best_C, max_iter=1000, random_state=45)\n",
    "optimized_log_reg.fit(X_train, y_train)\n",
    "y_test_pred = optimized_log_reg.predict(X_test)\n",
    "# run the test again with the best C parameter\n",
    "\n",
    "print(\"Optimized test performance:\\n\", classification_report(y_test, y_test_pred))\n",
    "# see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab2daf-09cd-4420-8c72-fed94f9cad7a",
   "metadata": {},
   "source": [
    "After optimizing the C hyperparameter of logistic regression, for 50k and above, precision (0.75) increases slightly, while recall (0.58) and F1 score (0.65) decrease slightly. The optimization seems to have not worked very well :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc1154-9a1a-4e7d-846a-4c4c1c9568f2",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5120f7c-d729-44a0-9713-15add719960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance (Decision Tree):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17305\n",
      "           1       1.00      1.00      1.00      5487\n",
      "\n",
      "    accuracy                           1.00     22792\n",
      "   macro avg       1.00      1.00      1.00     22792\n",
      "weighted avg       1.00      1.00      1.00     22792\n",
      "\n",
      "Test performance (Decision Tree):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      7415\n",
      "           1       0.62      0.61      0.62      2354\n",
      "\n",
      "    accuracy                           0.82      9769\n",
      "   macro avg       0.75      0.75      0.75      9769\n",
      "weighted avg       0.82      0.82      0.82      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=45)\n",
    "dt_model.fit(X_train, y_train) \n",
    "# train model\n",
    "\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "# predict training and test sets\n",
    "\n",
    "print(\"Training performance (Decision Tree):\\n\", classification_report(y_train, y_train_pred))\n",
    "print(\"Test performance (Decision Tree):\\n\", classification_report(y_test, y_test_pred))\n",
    "# check the performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd05fa-b098-4269-bfa9-faf86859a540",
   "metadata": {},
   "source": [
    "I print a classification report for both the training and test sets of the Decision tree model to evaluate its performance and detect potential overfitting.\n",
    "\n",
    "The training set accuracy is 1.00, indicating that the model perfectly classified 100% of the training data. The precision, recall, and F1-score values for both classes (50k and below and over 50K) are also 1.00, meaning the model memorized the training data entirely. \n",
    "\n",
    "On the test set, the accuracy drops to 0.82, meaning the model correctly classified 82% of the test data. When we examine the class-wise performance we see that income class of 50k and below, the precision, recall, and F1-score values are 0.88, indicating consistent performance in correctly identifying this majority class. For the income class of over 50k, the precision is 0.62, meaning the model is correct in 62% of its predictions. The recall is 0.61, showing that it correctly identified 61% of the actual over 50k. These relatively low precision and recall values for the minority class resulted in an F1-score of 0.62, significantly lower than the F1-score for the 50k and below (0.88).\n",
    "\n",
    "The difference between the training accuracy (100%) and test accuracy (82%) highlights that the model is overfitting the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f33820d-3832-456e-a8d3-0b983458938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized training performance (Decision Tree):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17305\n",
      "           1       0.79      0.51      0.62      5487\n",
      "\n",
      "    accuracy                           0.85     22792\n",
      "   macro avg       0.82      0.73      0.76     22792\n",
      "weighted avg       0.84      0.85      0.84     22792\n",
      "\n",
      "Optimized training performance (Decision Tree):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      7415\n",
      "           1       0.78      0.49      0.60      2354\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.82      0.72      0.75      9769\n",
      "weighted avg       0.84      0.84      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=5,              \n",
    "    min_samples_split=15,     \n",
    "    min_samples_leaf=5,       \n",
    "    random_state=45\n",
    ")\n",
    "# some hyperparameter trials\n",
    "\n",
    "dt_model.fit(X_train, y_train) \n",
    "# train again\n",
    "\n",
    "y_train_pred_opt = dt_model.predict(X_train)\n",
    "y_test_pred_opt = dt_model.predict(X_test)\n",
    "# and performances\n",
    "\n",
    "\n",
    "print(\"Optimized training performance (Decision Tree):\\n\", classification_report(y_train, y_train_pred_opt))\n",
    "print(\"Optimized training performance (Decision Tree):\\n\", classification_report(y_test, y_test_pred_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c8a96-9e11-4ab8-9704-14923e9404cf",
   "metadata": {},
   "source": [
    "After applying hyperparameter tuning to the Decision tree model, I checked the result if the tuning worked. The optimized model shows clear improvements in terms of generalization and reduced overfitting.\n",
    "\n",
    "The training set accuracy of the optimized model is 0.85, compared to the previous overfitted model's perfect score of 1.00. This indicates that the model no longer memorizes the training data but instead learns more general patterns. For the income class 50k and below, the model achieves a precision of 0.86, a recall of 0.96, and an F1 score of 0.91, showing strong and consistent performance. However, for the income class of over 50k, the model’s performance drops, with a precision of 0.79, a recall of 0.51, and an F1 score of 0.62. \n",
    "\n",
    "On the test set, the optimized model achieves an accuracy of 0.84, only slightly lower than its training accuracy, indicating that the model generalizes well. For the 50k and below class, the precision (0.85), recall (0.96), and F1 score (0.90) values remain high, confirming the model’s ability to consistently classify the majority class. For the over 50k class, the precision is 0.78, the recall is 0.49, and the F1 score is 0.60, which aligns closely with the training results and confirms that overfitting has been reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746875f-ed0f-48db-ae7d-241332628196",
   "metadata": {},
   "source": [
    "#####  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd761516-962f-4724-bd9a-79ed3dd61a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17305\n",
      "           1       1.00      1.00      1.00      5487\n",
      "\n",
      "    accuracy                           1.00     22792\n",
      "   macro avg       1.00      1.00      1.00     22792\n",
      "weighted avg       1.00      1.00      1.00     22792\n",
      "\n",
      "Test performance (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      7415\n",
      "           1       0.74      0.62      0.68      2354\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.81      0.78      0.79      9769\n",
      "weighted avg       0.85      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=45, n_estimators=100)  \n",
    "# set the model with 100 trees\n",
    "rf_model.fit(X_train, y_train)  \n",
    "#train the model\n",
    "\n",
    "y_train_pred_forest = rf_model.predict(X_train)\n",
    "y_test_pred_forest = rf_model.predict(X_test)\n",
    "# and predictions\n",
    "\n",
    "print(\"Training performance (Random Forest):\\n\", classification_report(y_train, y_train_pred_forest))\n",
    "print(\"Test performance (Random Forest):\\n\", classification_report(y_test, y_test_pred_forest))\n",
    "# now performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a2544-8d0a-4273-90b1-5215fc6480cd",
   "metadata": {},
   "source": [
    "The Random forest model achieves again perfect performance on the training set, with an accuracy of 1.00 and precision, recall, and F1 scores of 1.00 for both classes. On the test set, the accuracy drops to 0.86, showing that the model generalizes better than the unoptimized Decision tree. For the income class of 50k and below, the model performs well, with an F1 score of 0.91. However, for the over 50k class, the precision is 0.74, recall is 0.62, and F1 score is 0.68, reflecting a moderate imbalance in the model’s performance across classes. The gap between training and test performance shows overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f46955-cbf8-4d99-8710-f628813e21a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "135 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\belki\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.85670403 0.85727444 0.85736217\n",
      " 0.85661639 0.857099   0.85727449 0.8563531  0.85731837 0.85740613\n",
      " 0.85587047 0.85666017 0.85731837 0.85604604 0.85683573 0.85674801\n",
      " 0.85587052 0.85670403 0.85666017 0.85442248 0.85573885 0.85595822\n",
      " 0.85442248 0.85573885 0.85595822 0.85569498 0.85608984 0.85591432\n",
      " 0.86038965 0.86091604 0.8608722  0.86047742 0.8617059  0.86210072\n",
      " 0.86113553 0.86183751 0.86157426 0.86117929 0.86047728 0.86052124\n",
      " 0.86135488 0.8614427  0.8613111  0.8615305  0.86060903 0.8605213\n",
      " 0.85995095 0.85854689 0.85911722 0.85995095 0.85854689 0.85911722\n",
      " 0.85951223 0.86012639 0.85951216 0.85863465 0.85867838 0.85837134\n",
      " 0.85964381 0.86008245 0.86074056 0.86232027 0.86153028 0.86183736\n",
      " 0.86078436 0.8621884  0.86161806 0.86065284 0.86126708 0.86144253\n",
      " 0.86056519 0.86117941 0.86135488 0.85898555 0.86025795 0.8607845\n",
      " 0.85898555 0.86025795 0.8607845  0.85999482 0.85942433 0.86038956]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one is better: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Optimized training performance (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     17305\n",
      "           1       0.91      0.75      0.82      5487\n",
      "\n",
      "    accuracy                           0.92     22792\n",
      "   macro avg       0.92      0.86      0.89     22792\n",
      "weighted avg       0.92      0.92      0.92     22792\n",
      "\n",
      "Optimized training performance (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      7415\n",
      "           1       0.78      0.60      0.68      2354\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.83      0.77      0.79      9769\n",
      "weighted avg       0.86      0.86      0.86      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         \n",
    "    'max_depth': [0, 10, 20, 30],        \n",
    "    'min_samples_split': [2, 5, 10],        \n",
    "    'min_samples_leaf': [1, 2, 4]            \n",
    "}\n",
    "#set parameters\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=45), param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "# model optimization with gridsearchCV \n",
    "\n",
    "print(\"Which one is better:\", grid.best_params_)\n",
    "# find better parameters \n",
    "\n",
    "optimized_rf_model = grid.best_estimator_  # get the best one\n",
    "y_train_pred_opt_2 = optimized_rf_model.predict(X_train)\n",
    "y_test_pred_opt_2 = optimized_rf_model.predict(X_test)\n",
    "#testing the model after optimization\n",
    "\n",
    "print(\"Optimized training performance (Random Forest):\\n\", classification_report(y_train, y_train_pred_opt_2))\n",
    "print(\"Optimized training performance (Random Forest):\\n\", classification_report(y_test, y_test_pred_opt_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791aade3-4eee-4a9b-9f1e-4c9cd52c87bd",
   "metadata": {},
   "source": [
    "After optimization, the Random Forest model shows improved generalization, with the training accuracy dropping to 0.92 (from 1.00) and the test accuracy remaining at 0.86, indicating reduced overfitting. The performance for the over 50k class has slightly improved, with an F1 score of 0.68, and class balance is better reflected. The optimized hyperparameters (max_depth:30, n_estimators:50) effectively balance the model's complexity, making it more generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa0355-f8d6-4a13-bebe-3bbd84fde383",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dfe61-abef-4211-b8ea-d9cb1a78b3db",
   "metadata": {},
   "source": [
    "Among the three models, Random forest performs the best overall due to its higher test accuracy (0.86) and balanced performance across classes. While Logistic regression showed no overfitting, its recall for the  over 50k class was lower (0.59) compared to Random Forest (0.62). The Decision tree model overfit heavily and had worse generalization compared to Random forest. When I evaluate all the results together, Random forest provided better learning and prediction for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9309c-455f-454c-8b6c-ba25e7200733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
